# Configuration file for the DINO detector
# Filename convention: 
#   - {detector}-{backbone}.yaml

# Currently based on the config: https://github.com/IDEA-Research/DINO/blob/main/config/DINO/DINO_4scale.py
---
detector: "dino"

backbone: "resnet50"

backbone_params:
  return_levels: [1, 2, 3]
  backbone_freeze_keywords: TODO see if I need this


positional_embedding_params:
  # The height and width temperature of the positional embedding equation (attention is all you need);
  # see models.layers.positional for more details
  pe_temperature_h: 40
  pe_temperature_w: 40

  # row/col normalize the poisitonal coordinates [0, 2pi)
  normalize: True

criterion_params:
  # TODO: comment
  aux_loss: True # TODO: might need to move this? 

detector:
  name: "dino"

  # Section D.4 of the DINO paper gives parameters used
  params:
    standard:
      num_feature_levels: 4

      # TODO: Comment
      query_dim: 4

      # TODO: comment
      num_patterns: 0

      # TODO: this might not be used? I could leave it in and just use not implemented error
      random_refpoints_xy: False
      fix_refpoints_hw: -1 # comment the options

    # Other DINO params (maybe put these under their own key)

    # TODO: comment
    two_stage:
      type: "standard" # ["no", "standard"]
      pat_embed: 0
      add_query_num: 0
      learn_wh: False
      keep_all_tokens: False
      two_stage_default_hw: 0.05 # TODO: figure out if this is used
      bbox_embed_share: False
      class_embed_share: False

    denoising:
      # Number of denoising_queries for an image; will be evenly distributed to each GT object 
      # in the image based on the num_objects for the image w/ the most objects in the batch; therefore 
      # images in the batch w/ less objects will have more denoise queries per GT; additionally, 
      # denoise_number will be multiplied by 2 use positive and negative queries; 
      # e.g., if the image with the higheset num_objects is 6, there will be at least 
      # (100//6)*2 = 32 denoise queries per GT object
      denoise_number: 100

      # NOTE: the bash script overrides this parameter to 1.0, which is different than the config
      #       TODO: the paper uses 0.4 so I should play around with this
      denoise_box_noise_scale: 1.0

      denoise_label_noise_ratio: 0.5 

      # TODO rename and see if I can just use the number of classes in the dataset
      denoise_labelbook_size: 91

    # deformable attention params; also contains some general dino params
    transformer:
      hidden_dim: 256
      num_heads: 8

      # Number of learnable object queries that are input into the decoder; maximum number of object 
      # predictions dino will produce (each a bounding box and class)
      num_queries: 900

      num_encoder_layers: 6
      num_decoder_layers: 6
      num_unicoder_layers: 0 # ? not sure what this is

      # dimension of feedforward layer
      ff_dim: 2048

      # dropout value and activation function for the encoder and decoder
      dropout: 0.0
      activation: "relu"

      # Whether to normalize at the end of the TransformerEncoder; the name doesn't really make sense
      pre_norm: False

      # TODO: comment
      return_intermediate_dec: True

      # TODO: Comment
      enc_n_points: 4
      dec_n_points: 4

      use_deformable_box_attn: False

      # TODO: comment
      box_attn_type: "roi_align"

      # Adds a 
      add_channel_attention: False


      # TODO: Might remove these params if the don't need to change
      dec_layer_number: null
      rm_dec_query_scale: True
      rm_self_attn_layers: null
      rm_detach: null

      # TODO: comment
      dec_pred_class_embed_share: True
      dec_pred_bbox_embed_share: True

      decoder_self_attn_type: "sa" # ['sa', 'ca_label', 'ca_content']
      decoder_module_seq: ["sa", "ca", "ffn"]

      embed_init_tgt: True

      # According to this github issue: https://github.com/IDEA-Research/DINO/issues/77#issuecomment-1537355105
      # the `look forward twice` (lft) mechanism is controlled by this parameter, but in the official
      # repo this is disabled by default; they report best metrics with the lft mechanism so it's
      # weird it's disabled by default; I'll have to play around with this parameter once I finish
      # implementing; Actually, I think this default case does use look forward twice in the else case
      # the if case is look forward once I think, so False seems correct
      use_detached_boxes_dec_out: False

      # Creates the decoder_query_bbox_pertuber; this is False by default and not used
      # still need to briefly understand the code in case it becomes important
      decoder_layer_noise: False
      dec_noise_params:
        dln_xy_noise: 0.2
        dln_hw_noise: 0.2






  



